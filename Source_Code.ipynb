{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Source_Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JUWc70jyTNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####### Code has been sourced and modelled as advised on https://scikit-learn.org/\n",
        "\n",
        "##### Help in understanding implemetation of Neural Networks was also taken from \n",
        "#### https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "all_features = ['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal']\n",
        "\n",
        "score_dic = {'age': 0, 'sex': 0, 'cp': 0, 'trestbps': 0, 'chol': 0, 'fbs': 0, 'restecg': 0, 'thalach': 0, 'exang': 0, 'oldpeak': 0, 'slope': 0, 'ca': 0, 'thal': 0}\n",
        "\n",
        "\n",
        "\n",
        "# %matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"/heartdata.csv\")\n",
        "\n",
        "\n",
        "bio_markers = dataset.drop(\"target\" ,axis = 1)\n",
        "# bio_markers = bio_markers.drop(\"cp\", axis = 1)\n",
        "# bio_markers = bio_markers.drop(\"ca\", axis = 1)\n",
        "# print(bio_markers)\n",
        "class_field = dataset[\"target\"]\n",
        "\n",
        "X, X_t, Y, Y_t = train_test_split(bio_markers, class_field, test_size = 0.20, random_state = 0)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QT9wrGpyzQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logistic_regression():\n",
        "\n",
        "\n",
        "    # Logistic LogisticRegression\n",
        "    logistic_analysis = LogisticRegression()\n",
        "\n",
        "    logistic_analysis.fit(X, Y)\n",
        "\n",
        "    logistic_predict = logistic_analysis.predict(X_t)\n",
        "\n",
        "    results_logistic = accuracy_score(logistic_predict, Y_t) * 100\n",
        "\n",
        "    return results_logistic\n",
        "\n",
        "\n",
        "# Naive Bayes\n",
        "\n",
        "def naive_bayes():\n",
        "\n",
        "\n",
        "    gaussian_algo = GaussianNB()\n",
        "\n",
        "    gaussian_algo.fit(X, Y)\n",
        "\n",
        "    gaussian_pred = gaussian_algo.predict(X_t)\n",
        "\n",
        "    gaussian_results = accuracy_score(gaussian_pred, Y_t) * 100\n",
        "    \n",
        "\n",
        "\n",
        "    # multi_algo = MultinomialNB()\n",
        "\n",
        "    # multi_algo.fit(X, Y)\n",
        "\n",
        "    # multi_pred = gaussian_algo.predict(X_t)\n",
        "\n",
        "    # multi_results = accuracy_score(multi_pred, Y_t) * 100\n",
        "    # # return multi_results\n",
        "    # print(\"other\", multi_results)\n",
        "\n",
        "\n",
        "    #### Bernoulli Removed\n",
        "\n",
        "\n",
        "    return gaussian_results\n",
        "\n",
        "# SVM Classifier\n",
        "\n",
        "def svm_classifier():\n",
        "\n",
        "    linear = svm.SVC(kernel = 'linear')\n",
        "    poly = svm.SVC(kernel = 'poly')\n",
        "    sigmoid = svm.SVC(kernel = 'sigmoid')\n",
        "\n",
        "    linear.fit(X, Y)\n",
        "    poly.fit(X, Y)\n",
        "    sigmoid.fit(X, Y)\n",
        "\n",
        "    pred1 = linear.predict(X_t)\n",
        "    pred2 = poly.predict(X_t)\n",
        "    pred3 = sigmoid.predict(X_t)\n",
        "\n",
        "    linear_res = accuracy_score(pred1, Y_t) * 100\n",
        "\n",
        "    \n",
        "\n",
        "    poly_res = accuracy_score(pred2, Y_t) * 100\n",
        "\n",
        "\n",
        "    sigmoid_res = accuracy_score(pred3, Y_t) * 100\n",
        "\n",
        "    # print(linear_res)\n",
        "\n",
        "\n",
        "    return linear_res\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "# K Nearest Neighbours\n",
        "\n",
        "def knn_classifier():\n",
        "\n",
        "\n",
        "    clf = KNeighborsClassifier(n_neighbors = 8)\n",
        "    \n",
        "    clf_pred = clf.fit(X, Y).predict(X_t)\n",
        "\n",
        "    clf_results = accuracy_score(clf_pred, Y_t) * 100\n",
        "\n",
        "    return clf_results\n",
        "\n",
        "\n",
        "#\n",
        "# Random Forest\n",
        "\n",
        "\n",
        "def rand_forest():\n",
        "\n",
        "\n",
        "\t\n",
        "########################################\n",
        "    larg_acc = 0\n",
        "\n",
        "## Chnage the number in the for loop to optimize the algorithm\n",
        "    # for x in range(2000):\n",
        "\n",
        "    for x in range(1500):\n",
        "\n",
        "        clf = RandomForestClassifier(random_state = x)\n",
        "        \n",
        "        clf.fit(X, Y)\n",
        "        clf_pred = clf.predict(X_t)\n",
        "        curr_acc = accuracy_score(clf_pred, Y_t) * 100\n",
        "\n",
        "        # Check for largest accuracy\n",
        "\n",
        "        if(curr_acc > larg_acc):\n",
        "            larg_acc = curr_acc\n",
        "            mode = x\n",
        "            \n",
        "    \n",
        "    clf = RandomForestClassifier(random_state = mode)\n",
        "\n",
        "    clf.fit(X, Y)\n",
        "    clf_pred = clf.predict(X_t)\n",
        "\n",
        "    \n",
        "    clf_results = accuracy_score(clf_pred, Y_t) * 100\n",
        "    \n",
        "\n",
        "    return clf_results\n",
        "\n",
        "# Neural Network\n",
        "### These Exisiting Layers May Not Give The Highest Accuracy Depending On the State Of The Dataset\n",
        "### Changing the Epochs may not give visible improvements after a certain point\n",
        "\n",
        "def neural_net():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # CHANGE THIS FOR CHANGING DIMENSIONS\n",
        "    model.add(Dense(12, activation = 'relu', input_dim = 13))\n",
        "    # model.add(Dense(12, activation = 'relu', input_dim = 12))\n",
        "    # model.add(Dense(12, activation = 'relu', input_dim = 11))\n",
        "    model.add(Dense(11, activation = 'relu'))\n",
        "    # model.add(Dense(11, activation = 'relu', input_dim = 12))\n",
        "\n",
        "    # model.add(Dense(12, activation = 'tanh', input_dim = 13))\n",
        "    # model.add(Dense(12, activation = 'selu', input_dim = 13))\n",
        "    # model.add(Dense(12, activation = 'elu', input_dim = 13))\n",
        "\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer= 'adam', metrics = ['accuracy'])\n",
        "\n",
        "    # Change epochs to change execution time \n",
        "    model.fit(X, Y, epochs = 2000)\n",
        "\n",
        "    neural_preds = model.predict(X_t)\n",
        "\n",
        "\n",
        "    neural_results = accuracy_score(neural_preds, Y_t) * 100\n",
        "\n",
        "\n",
        "    return neural_results\n",
        "\n",
        "\n",
        "def neural_net1():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # CHANGE THIS FOR CHANGING DIMENSIONS\n",
        "    # model.add(Dense(12, activation = 'relu', input_dim = 13))\n",
        "    model.add(Dense(12, activation = 'relu', input_dim = 12))\n",
        "    # model.add(Dense(12, activation = 'relu', input_dim = 11))\n",
        "    # model.add(Dense(11, activation = 'relu'))\n",
        "    # model.add(Dense(11, activation = 'relu', input_dim = 12))\n",
        "\n",
        "    model.add(Dense(1,activation ='sigmoid'))\n",
        "    # model.add(Dense(12, activation = 'tanh', input_dim = 13))\n",
        "    # model.add(Dense(12, activation = 'selu', input_dim = 13))\n",
        "    # model.add(Dense(12, activation = 'elu', input_dim = 13))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer= 'adam', metrics = ['accuracy'])\n",
        "\n",
        "    # Change epochs to change execution time \n",
        "    model.fit(X, Y, epochs = 2000)\n",
        "\n",
        "    neural_preds = model.predict(X_t)\n",
        "\n",
        "\n",
        "    neural_results = accuracy_score(neural_preds, Y_t) * 100\n",
        "\n",
        "\n",
        "    return neural_results"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XasO6NOMy6-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "lg_score = logistic_regression()\n",
        "nb_score = naive_bayes()\n",
        "svm_score = svm_classifier()\n",
        "knn_score = knn_classifier()\n",
        "\n",
        "### comment out only if you have lots of time\n",
        "\n",
        "\n",
        "# rand_forest_score = rand_forest()\n",
        "\n",
        "# ann_score = neural_net()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aW7o-Xeze8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b03ba68b-f943-4f69-ea59-f7cefb13bb1c"
      },
      "source": [
        "for i in all_features:\n",
        "\n",
        "\tdataset = pd.read_csv(\"/heartdata.csv\")\n",
        "\n",
        "\n",
        "\tbio_markers = dataset.drop(\"target\" , axis = 1)\n",
        "\n",
        "\tbio_markers = dataset.drop(i, axis = 1)\n",
        "\n",
        "\tclass_field = dataset[\"target\"]\n",
        "\n",
        "\tX, X_t, Y, Y_t = train_test_split(bio_markers, class_field, test_size = 0.20, random_state = 0)\n",
        "\n",
        "\n",
        "\tlg_score1 = logistic_regression()\n",
        "\tif lg_score1 > lg_score:\n",
        "\t\tscore_dic[i] = score_dic[i] - 1\n",
        "\telif lg_score1 < lg_score:\n",
        "\t\tscore_dic[i] = score_dic[i] + 1\n",
        "\n",
        "\tnb_score1 = naive_bayes()\n",
        "\tif nb_score1 > nb_score:\n",
        "\t\tscore_dic[i] = score_dic[i] - 1\n",
        "\telif nb_score1 < nb_score:\n",
        "\t\tscore_dic[i] = score_dic[i] + 1\n",
        "\n",
        "\tsvm_score1 = svm_classifier()\n",
        "\tif svm_score1 > svm_score:\n",
        "\t\tscore_dic[i] = score_dic[i] - 1\n",
        "\telif svm_score1 < svm_score:\n",
        "\t\tscore_dic[i] = score_dic[i] + 1\n",
        "\n",
        "\n",
        "\tknn_score1 = knn_classifier()\n",
        "\tif knn_score1 > knn_score:\n",
        "\t\tscore_dic[i] = score_dic[i] - 1\n",
        "\telif knn_score1 < knn_score:\n",
        "\t\tscore_dic[i] = score_dic[i] + 1\n",
        "\n",
        "\n",
        "# commented out currently due to the time it takes to execute them:\n",
        "\n",
        "\n",
        "\t# rand_forest_score1 = rand_forest()\n",
        "\t# if rand_forest_score1 > rand_forest_score:\n",
        "\t# \tscore_dic[i] = score_dic[i] - 1\n",
        "\t# elif rand_forest_score1 < rand_forest_score:\n",
        "\t# \tscore_dic[i] = score_dic[i] + 1\n",
        "\n",
        "\t# ann_score = neural_net1()\n",
        "\t# if ann_score1 > ann_score:\n",
        "\t# \tscore_dic[i] = score_dic[i] - 1\n",
        "\t# elif ann_score1 < ann_score:\n",
        "\t# \tscore_dic[i] = score_dic[i] + 1\n",
        "\n",
        "\n",
        "results = sorted(score_dic)\n",
        "print(results)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['age', 'ca', 'chol', 'cp', 'exang', 'fbs', 'oldpeak', 'restecg', 'sex', 'slope', 'thal', 'thalach', 'trestbps']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}